# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kRDCxL-4XaM9TXke_sdSs2UWuewcK_QQ
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

np.random.seed(42)
start_date = "2024-01-01"
days = 577
dates = pd.date_range(start=start_date, periods=days, freq="D")

posting_start_idx = 289
viral_boost = 0
records = []

def get_engagement_multiplier(hour):
    if 0 <= hour < 5:
        return np.random.uniform(0.1, 0.4)
    elif 5 <= hour < 11:
        return np.random.uniform(0.5, 0.7)
    elif 11 <= hour < 14:
        return np.random.uniform(1.0, 1.3)
    elif 14 <= hour < 17:
        return np.random.uniform(0.8, 1.1)
    elif 17 <= hour < 21:
        return np.random.uniform(1.3, 1.6)
    else:
        return np.random.uniform(0.6, 0.9)

for i, date in enumerate(dates):
    if i < posting_start_idx:
        continue

    n_posts = np.random.choice([0, 1, 2, 3], p=[0.05, 0.5, 0.25, 0.2])

    for p in range(n_posts):
        r = np.random.rand()
        if r < 0.7:
            hour_post = np.random.choice(range(9, 17))
        elif r < 0.9:
            hour_post = np.random.choice(range(18, 23))
        else:
            hour_post = np.random.choice(range(0, 9))

        upload_time = pd.Timestamp(date) + pd.Timedelta(hours=hour_post)

        viral_boost = 0

        growth_factor = 100000 + (i - posting_start_idx) * 80
        seasonality = 1.0 + 0.1 * np.sin(2 * np.pi * i / 180)
        base_views = growth_factor * seasonality

        if np.random.rand() < 0.01 and i > 250:
            views = np.random.randint(10_000_000, 30_000_000)
            like_rate = np.random.uniform(0.15, 0.30)
            viral_boost = views * 0.2

        elif np.random.rand() < 0.08:
            views = np.random.randint(1_000_000, 5_000_000)
            like_rate = np.random.uniform(0.10, 0.20)
            viral_boost = views * 0.1
        else:
            views = int(max(0, np.random.normal(base_views, base_views * 0.5) + viral_boost))
            like_rate = np.random.uniform(0.05, 0.15)
            if np.random.rand() < 0.05:
                like_rate = np.random.uniform(0.15, 0.30)

        viral_boost *= 0.25

        multiplier = get_engagement_multiplier(hour_post)

        likes = int(views * like_rate * multiplier)

        if views > 1_000_000:
            base_comment_rate = np.random.uniform(0.1, 0.2)
        else:
            base_comment_rate = np.random.uniform(0.15, 0.3)

        noise_comment = np.random.uniform(0, 0.01)
        comment_rate = max(0, base_comment_rate + noise_comment)
        comments = int(likes * comment_rate)

        if views > 1_000_000:
            base_share_rate = np.random.uniform(0.1, 0.2)
        else:
            base_share_rate = np.random.uniform(0.15, 0.2)

        noise_share = np.random.uniform(0, 0.01)
        share_rate = max(0, base_share_rate + noise_share)
        shares = int(likes * share_rate)

        records.append({
            "video_id": f"{date.strftime('%Y%m%d')}_{p+1}",
            "date": upload_time,
            "views": views,
            "likes": likes,
            "comments": comments,
            "shares": shares,
        })

engagement_df = pd.DataFrame(records)

eng_per_day = engagement_df.groupby(engagement_df["date"].dt.date)["views"].sum()
eng_per_day = eng_per_day.reindex(dates.date, fill_value=0)

products = {
    "Serum": 120_000,
    "Moisturizer": 150_000,
    "Cleanser": 90_000,
    "Sunscreen": 110_000
}

alpha_short_prod = {
    "Serum": 0.003,
    "Moisturizer": 0.004,
    "Cleanser": 0.006,
    "Sunscreen": 0.005
}

alpha_long_prod = {
    "Serum": 0.0015,
    "Moisturizer": 0.002,
    "Cleanser": 0.0025,
    "Sunscreen": 0.002
}

base_sales = {
    "Serum": 50,
    "Moisturizer": 60,
    "Cleanser": 100,
    "Sunscreen": 80
}

sales_records = []

price_map = {}

for prod, base_price in products.items():
  price_list = []
  for i in range(0, days, 90):
    p = int(np.random.normal(base_price, base_price * 0.05))
    price_list.extend([p] * min(90, days - i))
    price_map[prod] = np.array(price_list)

views_ema = pd.Series(eng_per_day).ewm(span=14, adjust=False).mean()
views_trend = pd.Series(eng_per_day).rolling(30, min_periods=1).mean()


for idx, d in enumerate(dates):
    for prod in products.keys():
        engagement_short = views_ema.iloc[idx]
        engagement_long = views_trend.iloc[idx]
        units = (
            base_sales[prod]
            + alpha_short_prod[prod] * engagement_short
            + alpha_long_prod[prod] * engagement_long
            + np.random.normal(0, 15)
        )

        if idx < posting_start_idx:
            units = base_sales[prod] + np.random.randint(-5, 5)

        units = max(0, int(units))

        revenue = units * price_map[prod][idx]
        sales_records.append([d, prod, units, price_map[prod][idx], revenue])

sales_df = pd.DataFrame(
    sales_records,
    columns=["date", "product", "sales_units", "unit_price", "revenue"]
)

engagement_df.to_csv("tiktok_engagement.csv", index=False)
sales_df.to_csv("sales_data_daily.csv", index=False)

print("Contoh data engagement (per video):")
print(engagement_df.head(10))
print("\nContoh data sales (per hari):")
print(sales_df.head(10))

df = pd.read_csv("tiktok_engagement.csv")
df.info()
df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S')

#Engagement Rate Calculation
df['like_rate'] = (df['likes'] / df['views']) * 100
df['comment_rate'] = (df['comments'] / df['views']) * 100
df['share_rate'] = (df['shares'] / df['views']) * 100
df['engagement_rate'] = ((df['likes'] + df['comments'] + df['shares']) / df['views']) * 100
avg_eng = df['engagement_rate'].mean()

print(f"Engagement Rate: {avg_eng:.2f}%")
print(f"Highest Engagement : {df['engagement_rate'].max():.2f}%")
print(f"Lowest Engagement : {df['engagement_rate'].min():.2f}%")

#Play vs Engagement Rate
plt.figure(figsize=(10,6))
sns.regplot(
    data = df,
    x = 'views',
    y = 'engagement_rate',
    scatter_kws = {'alpha': 0.5},
    line_kws = {'color': 'red'}
)

plt.xscale('log')
plt.title('Views vs Engagement Rate')
plt.show()

#Engagement by Hour
df['hour'] = df['date'].dt.hour

engagement_by_hour = df.groupby('hour')['engagement_rate'].mean()

plt.figure(figsize=(10,6))
sns.barplot(x=engagement_by_hour.index, y=engagement_by_hour.values)
plt.title('Engagement Rate by Hour')
plt.xlabel('Hour')
plt.ylabel('Engagement Rate')

#Best Posting Time
df['day_of_week'] = df['date'].dt.day_name()
day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']

heatmap_data = df.groupby(['day_of_week', 'hour'])['engagement_rate'].mean().reset_index()

heatmap_pivot = heatmap_data.pivot(index='day_of_week', columns='hour', values='engagement_rate')
heatmap_pivot = heatmap_pivot.reindex(day_order)

plt.figure(figsize=(10,6))
sns.heatmap(heatmap_pivot, cmap='YlGnBu', annot=True, fmt='.1f', cbar=False)
plt.title('Engagement Rate by Day of Week and Hour')
plt.xlabel('Hour')
plt.ylabel('Day of Week')

#Correlation Heatmap
corr_matrix = df[['views', 'likes', 'comments', 'shares','like_rate', 'comment_rate', 'share_rate']].corr()

plt.figure(figsize=(10,6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

df = pd.read_csv("sales_data_daily.csv")
df.info()
df['date'] = pd.to_datetime(df['date'])
revenue = df['revenue'].sum()
print(revenue)

#Total Revenue by Month
df['month'] = df['date'].dt.to_period('M')

sales_by_month = df.groupby('month')['revenue'].sum()

plt.figure(figsize=(14,6))
sns.barplot(x=sales_by_month.index.astype(str), y=sales_by_month.values)
plt.title('Total Revenue by Month')
plt.xlabel('Month')
plt.ylabel('Total Revenue')
plt.xticks(rotation=45)      # putar label 45 derajat
plt.tight_layout()
plt.show()

#Total Sales Units by Month
df['month'] = df['date'].dt.to_period('M')

sales_units_by_month = df.groupby('month')['sales_units'].sum()

plt.figure(figsize=(14,6))
sns.barplot(x=sales_by_month.index.astype(str), y=sales_by_month.values)
plt.title('Total Sales Units by Month')
plt.xlabel('Month')
plt.ylabel('Total Sales Units')
plt.xticks(rotation=45)      # putar label 45 derajat
plt.tight_layout()
plt.show()

#Total Sales per Product by Month
df['month'] = df['date'].dt.to_period('M')
sales_product_by_month = df.groupby(['month', 'product'])['sales_units'].sum().reset_index()
pivot_sales = sales_product_by_month.pivot(index="month", columns="product", values="sales_units")

pivot_sales.index = pivot_sales.index.to_timestamp()

x = np.arange(len(pivot_sales.index))      # posisi sumbu-x
width = 0.15                               # lebar bar tiap produk

fig, ax = plt.subplots(figsize=(10,6))

for i, product in enumerate(pivot_sales.columns):
    ax.bar(x + i*width,
           pivot_sales[product],
           width,
           label=product)

ax.set_xticks(x + width*(len(pivot_sales.columns)-1)/2)
ax.set_xticklabels(pivot_sales.index.strftime("%b %Y"), rotation=45)
ax.set_ylabel("Units Terjual")
ax.set_title("Penjualan per Produk per Bulan (Grouped Bar)")
ax.legend(title="Produk")
plt.tight_layout()
plt.show()

daily_eng = engagement_df.groupby(engagement_df['date'].dt.date).agg({
    'views':'sum',
    'likes':'sum',
    'comments':'sum',
    'shares':'sum'
}).reset_index().rename(columns={'index':'date'})

sales_daily = sales_df.copy()
sales_daily['date'] = sales_daily['date'].dt.date
sales_daily = sales_daily.reset_index(drop=True) # Reset index to avoid ambiguity

df_merge = pd.merge(sales_daily, daily_eng, on='date', how='left').fillna(0)

df_merge.info()

df_merge['engagement_rate'] = ((df_merge['likes'] + df_merge['comments'] + df_merge['shares']) / df_merge['views']) * 100
corr = df_merge[['sales_units','engagement_rate','views','likes','comments','shares']].corr()
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title("Korelasi Sales & Engagement")
plt.show()

plt.scatter(df_merge['views'], df_merge['sales_units'], alpha=0.5)
plt.xlabel("Views TikTok (harian)")
plt.ylabel("Sales Units (harian)")
plt.title("Hubungan Views TikTok vs Penjualan")
plt.show()